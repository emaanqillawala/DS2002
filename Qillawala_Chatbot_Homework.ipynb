{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0z0SE4eu90C"
      },
      "source": [
        "# Building a Chatbot Homework\n",
        "## Emaan Qillawala\n",
        "## DS 2002 4/10/24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Pg-mZfsCu90D"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "\n",
        "# Tensorflow is the program used to build the Chatbot\n",
        "#!pip install tensorflow\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "# Tip! Use TPU instead of CPU for a faster runtime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOxEVBdtu90E"
      },
      "source": [
        "### 1. Build a chatbot using Python/TF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "n5M_ViDzu90F"
      },
      "outputs": [],
      "source": [
        "# develop questions that Chatbot can understand\n",
        "\n",
        "questions = [\n",
        "    'Hello!',\n",
        "    'What is your mood for today?',\n",
        "    'Can you help me with something?',\n",
        "    'What is your favorite animal?',\n",
        "    'How do I make cereal?',\n",
        "    'Do you know the movie Wall-E?',\n",
        "    'Who won the NCAA Mens basketball tournament in 2019?',\n",
        "    'Where is Morocco located?',\n",
        "    'Where can I find the longest river in the United States?',\n",
        "    'What are the three primary colors?',\n",
        "    'Are you draining my computer battery?',\n",
        "    'What is acceleration due to gravity?',\n",
        "    'Can you talk to like a pirate?',\n",
        "    'Goodbye!'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EmH_RALPu90F"
      },
      "outputs": [],
      "source": [
        "# develop answers to Chatbot questions\n",
        "\n",
        "answers = [\n",
        "    'Hello there! I am Chatbot.',\n",
        "    'I am feeling good today! :)',\n",
        "    'Sure! What can I help you with?',\n",
        "    'Of course, my favorite animal is the robot.',\n",
        "    'You pour cereal into a bowl FIRST and then add milk. Enjoy!',\n",
        "    'I am a chatbot. What do you think?',\n",
        "    'UVA, wahoowa!',\n",
        "    'Morocco is a country located in Africa.',\n",
        "    'You can find the Mississippi River in many states, including Mississippi.',\n",
        "    'The three primary colors are Red, Blue, and Yellow.',\n",
        "    'That is not particularly due to me.',\n",
        "    'Acceleration due to gravity is approximately 9.8 m/s^2.',\n",
        "    'Arggg! Yes I can me hearty!',\n",
        "    'Goodbye user. See you next time!'\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxUrbzDtu90F"
      },
      "source": [
        "### 2. Customize and train Chatbot responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MUm-Ng7Mu90G"
      },
      "outputs": [],
      "source": [
        "# tokenize the sentences for Chatbot to understand\n",
        "\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(questions + answers)\n",
        "sequences_questions = tokenizer.texts_to_sequences(questions)\n",
        "sequences_answers = tokenizer.texts_to_sequences(answers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ai8TuXzcu90G"
      },
      "outputs": [],
      "source": [
        "# pad the sequences -> giving input sequences a specified length\n",
        "\n",
        "max_length = max(max(len(seq) for seq in sequences_questions), max(len(seq) for seq in sequences_answers))\n",
        "padded_questions = tf.keras.preprocessing.sequence.pad_sequences(sequences_questions, maxlen=max_length, padding='post')\n",
        "padded_answers = tf.keras.preprocessing.sequence.pad_sequences(sequences_answers, maxlen=max_length, padding='post')\n",
        "\n",
        "# define the vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2OQ-9f2-u90G"
      },
      "outputs": [],
      "source": [
        "# define model parameters\n",
        "\n",
        "embedding_dim = 256\n",
        "units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kgQHgEXZu90G"
      },
      "outputs": [],
      "source": [
        "# define the encoder model to generate Chatbot outputs\n",
        "\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "encoder_embedding = Embedding(vocab_size, embedding_dim)(encoder_inputs)\n",
        "encoder_outputs, state_h, state_c = LSTM(units, return_state=True)(encoder_embedding)\n",
        "encoder_states = [state_h, state_c]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "epANYUu_u90G"
      },
      "outputs": [],
      "source": [
        "# define the decoder model to generate Chatbot outputs\n",
        "\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "decoder_embedding = Embedding(vocab_size, embedding_dim)(decoder_inputs)\n",
        "decoder_lstm = LSTM(units, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "decoder_dense = Dense(vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JusLQnrLu90H",
        "outputId": "c90220d0-389a-4e92-8198-167da6dc1d26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, None, 256)            26624     ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, None, 256)            26624     ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 [(None, 1024),               5246976   ['embedding[0][0]']           \n",
            "                              (None, 1024),                                                       \n",
            "                              (None, 1024)]                                                       \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               [(None, None, 1024),         5246976   ['embedding_1[0][0]',         \n",
            "                              (None, 1024),                          'lstm[0][1]',                \n",
            "                              (None, 1024)]                          'lstm[0][2]']                \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, None, 104)            106600    ['lstm_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10653800 (40.64 MB)\n",
            "Trainable params: 10653800 (40.64 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# define the seq2seq model using the encoder and decoder models\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# summary of the model -> shows all of the components of the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9REsY_0Tu90H"
      },
      "source": [
        "### 3. Practice basic inputs/outputs\n",
        "### -> ex: hello and goodbye"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0m-nxV8-u90I"
      },
      "outputs": [],
      "source": [
        "# prepare decoder input data that contains the start token only\n",
        "\n",
        "decoder_input_data = np.zeros_like(padded_answers)\n",
        "decoder_input_data[:, 0] = 1  # 1 is the start token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6X4toes0u90I",
        "outputId": "7d79fac6-103d-4111-ce13-b8aa4cde61f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "7/7 [==============================] - 12s 1s/step - loss: 4.2014 - accuracy: 0.3393\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 3.4441 - accuracy: 0.3810\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 3.3549 - accuracy: 0.3929\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 3.0754 - accuracy: 0.3869\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 3.0927 - accuracy: 0.3929\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 3.0077 - accuracy: 0.3929\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 7s 996ms/step - loss: 3.1436 - accuracy: 0.3690\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.8819 - accuracy: 0.3988\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 7s 986ms/step - loss: 2.8587 - accuracy: 0.3810\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.8322 - accuracy: 0.3988\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.7680 - accuracy: 0.3869\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 2.7588 - accuracy: 0.3869\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.6545 - accuracy: 0.4048\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 7s 997ms/step - loss: 2.5710 - accuracy: 0.3988\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.5201 - accuracy: 0.3988\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 2.6493 - accuracy: 0.3869\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.5391 - accuracy: 0.4167\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.3713 - accuracy: 0.4048\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 7s 995ms/step - loss: 2.3339 - accuracy: 0.3869\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.7481 - accuracy: 0.4107\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 7s 977ms/step - loss: 2.3922 - accuracy: 0.3810\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.2638 - accuracy: 0.4167\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 7s 975ms/step - loss: 2.1796 - accuracy: 0.4286\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.3562 - accuracy: 0.4226\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 7s 985ms/step - loss: 2.1285 - accuracy: 0.4107\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.3601 - accuracy: 0.3690\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 2.2278 - accuracy: 0.4226\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 7s 998ms/step - loss: 2.0969 - accuracy: 0.3869\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.8919 - accuracy: 0.4048\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 1.9657 - accuracy: 0.3988\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.0568 - accuracy: 0.4226\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 2.1985 - accuracy: 0.4286\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.8873 - accuracy: 0.3988\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 1.9096 - accuracy: 0.4524\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 2.2065 - accuracy: 0.3988\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.7291 - accuracy: 0.4583\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 7s 979ms/step - loss: 1.6836 - accuracy: 0.4345\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.7184 - accuracy: 0.3988\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 1.6257 - accuracy: 0.4583\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.5673 - accuracy: 0.4167\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 1.6086 - accuracy: 0.4048\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.1169 - accuracy: 0.4107\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.5301 - accuracy: 0.4345\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 1.5439 - accuracy: 0.4702\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.3467 - accuracy: 0.4821\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 7s 997ms/step - loss: 1.3824 - accuracy: 0.4762\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.7846 - accuracy: 0.4167\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 1.5641 - accuracy: 0.4583\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.3805 - accuracy: 0.4881\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.2966 - accuracy: 0.4881\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.2424 - accuracy: 0.4702\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.6535 - accuracy: 0.4583\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 1.5624 - accuracy: 0.3929\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.4352 - accuracy: 0.4583\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 1.3846 - accuracy: 0.5060\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.4779 - accuracy: 0.4286\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.2188 - accuracy: 0.5298\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.1469 - accuracy: 0.4762\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.9952 - accuracy: 0.6131\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 1.1697 - accuracy: 0.5536\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.6270 - accuracy: 0.4762\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 1.2008 - accuracy: 0.5774\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.2563 - accuracy: 0.5238\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.0285 - accuracy: 0.5536\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 1.3872 - accuracy: 0.3929\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.0736 - accuracy: 0.5833\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.9742 - accuracy: 0.5476\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.4080 - accuracy: 0.4405\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.9184 - accuracy: 0.5536\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.9688 - accuracy: 0.5833\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.1036 - accuracy: 0.5536\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 7s 979ms/step - loss: 1.8377 - accuracy: 0.4762\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.2090 - accuracy: 0.5417\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.7805 - accuracy: 0.6786\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.6598 - accuracy: 0.7321\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.8316 - accuracy: 0.6607\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.2175 - accuracy: 0.4940\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.9923 - accuracy: 0.5893\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 1.4068 - accuracy: 0.5179\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.8525 - accuracy: 0.5476\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 1.2623 - accuracy: 0.5595\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.7017 - accuracy: 0.6667\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.5826 - accuracy: 0.8274\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.2630 - accuracy: 0.5417\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.0496 - accuracy: 0.5357\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.8168 - accuracy: 0.6250\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.9279 - accuracy: 0.6131\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.7709 - accuracy: 0.7143\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.6766 - accuracy: 0.6845\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.9259 - accuracy: 0.6012\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.5285 - accuracy: 0.7857\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.5110 - accuracy: 0.8214\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 1.4965 - accuracy: 0.4643\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.4574 - accuracy: 0.6310\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 7s 993ms/step - loss: 1.0881 - accuracy: 0.6131\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.6351 - accuracy: 0.6726\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.5185 - accuracy: 0.7619\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.3630 - accuracy: 0.8750\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.3073 - accuracy: 0.8929\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 7s 996ms/step - loss: 0.2637 - accuracy: 0.9167\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fcb7c67bf70>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# train the model with the decoder input data and define number of epochs\n",
        "\n",
        "model.fit([padded_questions, decoder_input_data], np.expand_dims(padded_answers, -1), batch_size=2, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Ygbz27A2u90I"
      },
      "outputs": [],
      "source": [
        "# implement the Chatbot function to talk to Chatbot\n",
        "## process the inputs\n",
        "## produce the outputs\n",
        "\n",
        "def preprocess_input_text(input_text):\n",
        "    sequence = tokenizer.texts_to_sequences([input_text])\n",
        "    padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=max_length, padding='post')\n",
        "    return padded_sequence\n",
        "\n",
        "def generate_response(input_sequence):\n",
        "    response_sequence = np.zeros((1, max_length))\n",
        "    response_sequence[0, 0] = 1  # Start token\n",
        "    for i in range(1, max_length):\n",
        "        prediction = model.predict([input_sequence, response_sequence]).argmax(axis=2)\n",
        "        response_sequence[0, i] = prediction[0, i-1]\n",
        "        if prediction[0, i-1] == 2:  # End token\n",
        "            break\n",
        "    return response_sequence\n",
        "\n",
        "def sequence_to_text(sequence):\n",
        "    return ' '.join(tokenizer.index_word.get(i, '') for i in sequence if i > 2)\n",
        "\n",
        "def chat_with_bot(input_text):\n",
        "    input_sequence = preprocess_input_text(input_text)\n",
        "    response_sequence = generate_response(input_sequence)\n",
        "    response_text = sequence_to_text(response_sequence[0])\n",
        "    return response_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYeI1CMfu90I",
        "outputId": "89ebdcbb-edcf-40e7-9e41-1021abc68eab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: Can you help me with something?\n",
            "1/1 [==============================] - 0s 152ms/step\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "1/1 [==============================] - 0s 108ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "1/1 [==============================] - 0s 111ms/step\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "1/1 [==============================] - 0s 106ms/step\n",
            "1/1 [==============================] - 0s 109ms/step\n",
            "Bot: sure what can i help with think\n"
          ]
        }
      ],
      "source": [
        "# Chat with Chatbot!\n",
        "\n",
        "input_text = \"Can you help me with something?\"\n",
        "print(f\"You: {input_text}\")\n",
        "print(f\"Bot: {chat_with_bot(input_text)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzJErC8Xu90I",
        "outputId": "8f067433-f9f6-4345-d0b2-4d8805ee4f6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start chatting with the bot! Type 'done' to exit.\n",
            "You: Hello@\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "Bot: goodbye user see next time\n",
            "You: Hello!\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "Bot: goodbye user see next time\n",
            "You: How do I make cereal?\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "1/1 [==============================] - 0s 88ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "Bot: pour cereal into a bowl first and then add milk\n",
            "You: done\n"
          ]
        }
      ],
      "source": [
        "# create an interactive box to talk to Chatbot\n",
        "\n",
        "print(\"Start chatting with the bot! Type 'done' to exit.\")\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == 'done':\n",
        "        break\n",
        "    response = chat_with_bot(user_input)\n",
        "    print(f\"Bot: {response}\")\n",
        "\n",
        "# include an option to end the chat by typing 'done' into the box"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}